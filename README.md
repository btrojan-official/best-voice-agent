# Best Voice Agent üéôÔ∏è

> **Enterprise-grade AI voice assistant for real-time customer support with comprehensive observability and analytics**

A production-ready, scalable voice AI agent that handles multiple concurrent conversations with advanced monitoring, cost tracking, and easy deployment via Docker Compose.

---

## ‚ú® Key Features

### üåç **Multi-Language Support**
Supports conversations in multiple languages out of the box - the agent automatically adapts to the user's language using advanced LLM capabilities.

### ‚ö° **Asynchronous Architecture**
- **Concurrent Call Handling**: Backend built with FastAPI's async framework to handle multiple simultaneous conversations
- **Non-blocking Operations**: All I/O operations (LLM calls, TTS, transcription) run asynchronously
- **Scalable Design**: Ready for high-volume production deployments

### üöÄ **Blazing Fast Performance**
- **Groq Integration**: Leverages ultra-fast Groq models (70B parameter models with sub-second response times)
- **Optimized Streaming**: Real-time response streaming for minimal latency
- **Smart Caching**: Precomputed audio for instant greetings and acknowledgments

### üìä **Comprehensive Observability**
- **Full Conversation Transcripts**: Complete records of all voice interactions
- **Automatic Summaries**: AI-generated summaries of each conversation
- **Cost Analytics**: Real-time cost tracking per call and system-wide
- **Performance Metrics**: Model latency tracking and performance analytics
- **Usage Statistics**: Token counts, API call tracking, and resource utilization

### üéõÔ∏è **Complete Customization**
- **Admin Dashboard**: Web-based control panel for system configuration
- **Dynamic Settings**: Adjust AI behavior, temperature, and model selection without code changes
- **Custom Data Collection**: Configure what information the agent should gather from customers
- **Flexible Prompts**: Easily customize agent personality and capabilities

### üß† **Intelligent History Management**
- **Long-Short Term Memory**: Efficient conversation summarization for extended interactions
- **Context Preservation**: Maintains conversation context while reducing token usage
- **Automatic Cleanup**: Stale pending calls auto-complete after 3 minutes of inactivity

### üõ°Ô∏è **Robust Error Handling**
- **Graceful Degradation**: Continues operation even if individual services fail
- **Comprehensive Logging**: Detailed error tracking and debugging information
- **Fallback Mechanisms**: Placeholder responses when APIs are unavailable
- **Health Checks**: Built-in monitoring for service availability

### üê≥ **Simple Deployment**
- **One-Command Setup**: Full stack deployment with `docker-compose up`
- **Containerized Services**: Isolated, reproducible environments
- **Volume Persistence**: Data and logs persisted across restarts
- **Production Ready**: Health checks, restart policies, and optimized builds included

---

## üì∏ Screenshots

### Admin Dashboard - Call Management
*View all conversations with real-time status updates*

![Admin Calls Dashboard](imgs/1.png)

### Conversations live transcription
*See the detailed information with real-time status updates*

![Conversation info](imgs/5.png)

### Statistics & Analytics
*Comprehensive usage metrics, cost tracking, and performance analytics*

![Statistics Dashboard](imgs/2.png)

### Configuration Settings
*Customize AI behavior, model selection, and data collection requirements*

![Settings Panel](imgs/3.png)

### Live Chat Interface
*Clean, intuitive voice chat experience for end users*

![Chat Interface](imgs/4.png)

---

## üèóÔ∏è Architecture

### Technology Stack

**Backend**
- **FastAPI**: High-performance async web framework
- **LlamaIndex**: LLM orchestration and tool calling
- **OpenRouter/Groq**: Multi-provider LLM access
- **ElevenLabs**: Neural text-to-speech
- **Groq Whisper**: Fast speech-to-text transcription
- **WebSocket**: Real-time bidirectional communication

**Frontend**
- **React 18**: Modern UI framework
- **TypeScript**: Type-safe development
- **Vite**: Lightning-fast build tool
- **React Router**: Client-side routing
- **MediaRecorder API**: Browser audio capture

**Infrastructure**
- **Docker & Docker Compose**: Containerized deployment
- **Nginx**: Production-grade web server
- **JSON Storage**: Simple, file-based persistence

---

## üìÅ Project Structure

```
best-voice-agent/
‚îú‚îÄ‚îÄ backend/                      # FastAPI backend service
‚îÇ   ‚îú‚îÄ‚îÄ agent/                    # AI agent core
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py             # Main agent implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py           # System prompts & templates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools.py             # Function calling tools
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # JSON database operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py           # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ routers/                  # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin.py             # Admin panel APIs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.py              # WebSocket chat endpoint
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utility modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tts.py               # Text-to-speech service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription.py     # Speech-to-text service
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ precomputed_audio.py # Audio caching
‚îÇ   ‚îú‚îÄ‚îÄ data/                     # Persisted data (volumes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calls.json           # Call records
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.json        # Configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stats.json           # Analytics
‚îÇ   ‚îú‚îÄ‚îÄ logs/                     # Application logs
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ auth.py                   # JWT authentication
‚îÇ   ‚îú‚îÄ‚îÄ test_apis.py             # API validation script
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile               # Backend container config
‚îÇ
‚îú‚îÄ‚îÄ frontend/                     # React frontend application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/               # Page components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat.tsx         # Customer chat interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AdminCalls.tsx   # Call management
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AdminStats.tsx   # Analytics dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AdminSettings.tsx # Configuration panel
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AdminLogin.tsx   # Authentication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # API clients
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts           # REST API service
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.ts          # Auth service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types.ts             # TypeScript definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.ts            # App configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.tsx             # Application entry
‚îÇ   ‚îú‚îÄ‚îÄ public/                  # Static assets
‚îÇ   ‚îú‚îÄ‚îÄ package.json             # Node dependencies
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Frontend container config
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf               # Nginx configuration
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml           # Multi-container orchestration
‚îú‚îÄ‚îÄ .env.example                 # Environment template
‚îî‚îÄ‚îÄ README.md                    # This file
```

---

## üöÄ Quick Start

### Prerequisites

**API Keys Required:**
- [OpenRouter API Key](https://openrouter.ai/) - For LLM access (Claude, GPT, etc.)
- [ElevenLabs API Key](https://elevenlabs.io/) - For text-to-speech
- [Groq API Key](https://groq.com/) - For fast speech-to-text transcription

### üê≥ Option 1: Docker Compose (Recommended)

The fastest way to get started. Requires only Docker and Docker Compose installed.

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/best-voice-agent.git
cd best-voice-agent

# 2. Configure environment variables
cp .env.example .env

# 3. Edit .env and add your API keys
nano .env  # or use your preferred editor

# Required configuration:
# OPENROUTER_API_KEY=your_openrouter_key_here
# ELEVENLABS_API_KEY=your_elevenlabs_key_here
# GROQ_API_KEY=your_groq_key_here

# 4. Start all services
docker-compose up -d

# 5. Check service health
docker-compose ps

# 6. View logs (optional)
docker-compose logs -f
```

**Access the application:**
- üéØ **Customer Chat**: http://localhost/chat
- üîß **Admin Panel**: http://localhost/admin
- üì° **API Docs**: http://localhost:8000/docs
- ‚ù§Ô∏è **Health Check**: http://localhost:8000/health

**Default admin credentials:**
- Username: `admin`
- Password: `admin123`
- ‚ö†Ô∏è Change these in production via `.env` file

**Stopping the application:**
```bash
# Stop services
docker-compose down

# Stop and remove volumes (deletes data)
docker-compose down -v
```

---

### üíª Option 2: Manual Setup (Development)

For local development without Docker.

#### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create Python virtual environment
python3 -m venv venv

# Activate virtual environment
# On Linux/Mac:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp ../.env.example .env
# Edit .env with your API keys

# (Optional) Test API connections
python test_apis.py

# Start backend server
python main.py
```

**Backend will be available at:** `http://localhost:8000`

#### Frontend Setup

Open a new terminal:

```bash
# Navigate to frontend directory
cd frontend

# Install Node.js dependencies
npm install

# Configure environment (optional - defaults work for local)
cp .env.example .env

# Start development server
npm run dev
```

**Frontend will be available at:** `http://localhost:5173`

---

## üß™ Testing API Connections

Before starting the application, verify your API keys are working:

```bash
cd backend
python test_apis.py
```

This will test:
- ‚úÖ OpenRouter API connectivity and model access
- ‚úÖ ElevenLabs TTS API and voice generation
- ‚úÖ Groq Whisper API and transcription service

---

## üìñ Usage Guide

### Customer Chat Interface

1. Navigate to `http://localhost/chat` (or `http://localhost:5173/chat` for dev mode)
2. Click **"Call Customer Support"** to initiate a conversation
3. **Hold the "Hold to Speak" button** while talking
4. **Release the button** to send your audio
5. The agent will:
   - üé§ Transcribe your speech
   - ü§ñ Process with AI
   - üîä Respond with voice + text
6. Continue the conversation naturally
7. Call auto-completes after 3 minutes of inactivity

### Admin Dashboard

#### Login
1. Navigate to `http://localhost/admin` (or `http://localhost:5173/admin` for dev mode)
2. Enter credentials (default: `admin` / `admin123`)
3. Access the control panel

#### Calls Management
- **View all conversations** with status badges (Pending/Completed/Error)
- **Click any call** to view full transcript and details
- **Filter and search** through conversation history
- **Auto-refresh** every 5 seconds for real-time updates
- **Automatic cleanup** of stale pending calls (3+ min inactive)

#### Statistics Dashboard
Monitor system-wide metrics:
- üìä **Total Calls**: Pending, completed, and error counts
- üí∞ **Cost Analytics**: LLM, transcription, and TTS costs
- üìà **Usage Statistics**: Tokens, characters, API calls
- ‚ö° **Performance Metrics**: Model latency per 100 tokens
- üìÖ **Time-based tracking**: Last updated timestamps

#### Settings Panel
Customize agent behavior:
- ü§ñ **Model Selection**: Choose from OpenRouter or Groq models
- üå°Ô∏è **Temperature**: Adjust response creativity (0.0 - 1.0)
- üíµ **Pricing Configuration**: Set cost per token/character
- üìã **Information Gathering**: Define what data to collect from customers
  - Add custom fields (e.g., order_id, customer_name)
  - Provide descriptions for agent context
  - Remove or modify existing fields

---

## ‚öôÔ∏è Configuration

### Environment Variables

Create `.env` file in the project root:

```bash
# ======================
# API Keys (Required)
# ======================
OPENROUTER_API_KEY=your_openrouter_api_key_here
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# Voice Configuration
ELEVENLABS_VOICE_ID=DODLEQrClDo8wCz460ld  # or your custom voice ID

# ======================
# API Base URLs
# ======================
# Customize if using proxies or different endpoints
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1/
ELEVENLABS_BASE_URL=https://api.elevenlabs.io/v1/
GROQ_BASE_URL=https://api.groq.com/openai/v1/

# ======================
# Model Configuration
# ======================
# Groq models: openai/gpt-oss-120b, llama-3.3-70b-versatile, llama-3.1-70b-versatile
# OpenRouter: anthropic/claude-3.5-sonnet, google/gemini-pro-1.5, etc.
DEFAULT_MODEL=openai/gpt-oss-120b
TRANSCRIPTION_MODEL=whisper-large-v3
ESTIMATED_TOKEN_LENGTH=4  # Characters per token estimate

# ======================
# Admin Credentials
# ======================
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123  # ‚ö†Ô∏è Change in production!

# ======================
# Server Configuration
# ======================
PORT=8000

# ======================
# CORS Settings
# ======================
# Comma-separated list of allowed origins
CORS_ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000,http://localhost,http://localhost:80
```

### Model Options

**Groq Models (Fastest, Free Tier Available):**
- `openai/gpt-oss-120b` - Best balance of speed and quality
- `llama-3.3-70b-versatile` - Very fast, good quality
- `moonshotai/kimi-k2-instruct-0905` - Reliable, fast
- Many other available via groq.com api

**OpenRouter Models (More Variety):**
- `anthropic/claude-4.5-sonnet` - Excellent quality, moderate speed
- `z-ai/glm-5` - Good quality - pretty slow
- `google/gemini-3-pro-preview` - Google's latest
- Many more available via OpenRouter catalog

---

## üí∞ Cost Tracking & Analytics

The system provides comprehensive cost estimation and tracking:

### Per-Call Metrics
- **LLM Costs**: Input and output token costs
- **Transcription**: Speech-to-text processing costs  
- **TTS**: Text-to-speech generation costs
- **Total Cost**: Aggregate cost per conversation

### System-Wide Analytics
- **Historical Tracking**: Cumulative costs over time
- **Model Performance**: Latency per 100 tokens by model
- **Usage Patterns**: Token and character consumption
- **API Call Counts**: Total requests to each service

### Configurable Pricing
Set your own pricing in the admin panel:
- Price per million input tokens
- Price per million output tokens
- Price per 5 seconds of transcription
- Price per 10k TTS characters

---

## üîß Development

### Adding Custom Tools

Edit `backend/agent/tools.py` to add new function calling capabilities:

```python
def custom_tool(self, param: str) -> dict:
    """Your custom tool description."""
    # Implementation
    return {"status": "success"}
```

### Customizing Prompts

Modify agent behavior in `backend/agent/prompts.py`:

```python
SYSTEM_PROMPT = """
Your custom system prompt here...
"""
```

### Adding API Endpoints

Create new routes in `backend/routers/`:

```python
@router.get("/custom-endpoint")
async def custom_endpoint():
    return {"data": "response"}
```

### Frontend Pages

Add new React pages in `frontend/src/pages/`:

```tsx
export default function CustomPage() {
  return <div>Custom Page Content</div>;
}
```

---

## üêõ Troubleshooting

### Docker Issues

**Container won't start:**
```bash
# Check container logs
docker-compose logs backend
docker-compose logs frontend

# Rebuild containers
docker-compose down
docker-compose up -d --build
```

**Port already in use:**
```bash
# Change ports in docker-compose.yml
# Frontend: ports: "8080:80"  (change 80 to 8080)
# Backend: ports: "8001:8000"  (change 8000 to 8001)
```

### WebSocket Connection Issues

**Connection refused:**
- Verify backend is running on port 8000
- Check CORS configuration in `backend/main.py`
- Ensure `CORS_ALLOWED_ORIGINS` includes your frontend URL

**Connection drops frequently:**
- Check firewall settings
- Verify network stability
- Increase timeout values if on slow connection

### Audio Issues

**Microphone not working:**
- Grant microphone permissions in browser
- Use HTTPS in production (required for MediaRecorder API)
- Test with different browsers (Chrome/Firefox recommended)

**No audio playback:**
- Check browser audio permissions
- Verify ElevenLabs API key is valid
- Check network/firewall blocking audio endpoints

### API Errors

**401 Unauthorized:**
- Verify API keys in `.env` file
- Check admin credentials for dashboard access
- Ensure JWT token hasn't expired (admin panel)

**404 Not Found / URL Errors:**
- Ensure base URLs in `.env` end with trailing slash `/`
- Example: `GROQ_BASE_URL=https://api.groq.com/openai/v1/`

**429 Rate Limit:**
- Check API quota limits
- Implement rate limiting in production
- Consider upgrading API plans

**500 Internal Server Error:**
```bash
# Check backend logs
docker-compose logs backend

# Or manually:
tail -f backend/logs/app.log
```

### Performance Issues

**Slow responses:**
- Switch to faster Groq models (e.g., `llama-3.1-8b-instant`)
- Reduce `max_tokens` in model configuration
- Check network latency to API providers

**High costs:**
- Use cheaper models (Groq models are often free/cheaper)
- Optimize prompt lengths
- Monitor token usage in admin statistics

---

## üìö API Documentation

Interactive API documentation available when backend is running:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

### Key Endpoints

**Public:**
- `GET /` - Health check
- `POST /api/call/start` - Start new call
- `WS /api/call/ws/{call_id}` - WebSocket for voice/text streaming

**Admin (Requires Authentication):**
- `POST /api/admin/login` - Admin authentication
- `GET /api/admin/calls` - List all calls
- `GET /api/admin/calls/{call_id}` - Call details
- `GET /api/admin/stats` - System statistics
- `GET /api/admin/settings` - Get configuration
- `PATCH /api/admin/settings` - Update configuration

---

## üö¢ Production Deployment

### Docker Compose (Recommended)

```bash
# 1. Set production environment variables
nano .env
# Change ADMIN_PASSWORD to strong password
# Add production CORS origins

# 2. Build and start
docker-compose up -d --build

# 3. Configure reverse proxy (Nginx/Traefik)
# Point to localhost:80 for frontend
# Point to localhost:8000 for backend API

# 4. Set up SSL/TLS certificates (Let's Encrypt recommended)

# 5. Configure monitoring and logging
```

### Security Checklist

- ‚úÖ Change default admin credentials
- ‚úÖ Use HTTPS/WSS in production
- ‚úÖ Set secure CORS origins
- ‚úÖ Enable firewall rules
- ‚úÖ Rotate API keys regularly
- ‚úÖ Monitor logs for suspicious activity
- ‚úÖ Implement rate limiting
- ‚úÖ Regular backups of data directory

### Scaling Considerations

- **Horizontal Scaling**: Run multiple backend containers behind load balancer
- **Database**: Migrate from JSON to PostgreSQL/MongoDB for high volume
- **Caching**: Add Redis for session management and caching
- **CDN**: Serve frontend assets via CDN
- **Monitoring**: Implement Prometheus + Grafana for metrics

---

## üìù License

MIT License - see LICENSE file for details

---

## ü§ù Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow existing code style (use Black for Python, Prettier for TypeScript)
- Add TypeScript types for all new code
- Include comprehensive error handling
- Add logging for debugging
- Update documentation for new features
- Test thoroughly before submitting PR

---

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/best-voice-agent/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/best-voice-agent/discussions)
- **Documentation**: See `/docs` directory

---

## üôè Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [LlamaIndex](https://www.llamaindex.ai/) - LLM orchestration
- [React](https://react.dev/) - UI framework
- [OpenRouter](https://openrouter.ai/) - LLM API aggregator
- [ElevenLabs](https://elevenlabs.io/) - Neural voice synthesis
- [Groq](https://groq.com/) - Ultra-fast LLM inference

---

**Made with ‚ù§Ô∏è for building better voice AI experiences**
